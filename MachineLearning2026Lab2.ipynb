{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23b8c20",
   "metadata": {},
   "source": [
    "# Lab Assignment Two: Exploring Image Data\n",
    "\n",
    "Author: Jadon Swearingen, Andy Su, Emilio Munoz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb4d800",
   "metadata": {},
   "source": [
    "Lab Assignment Two: Exploring Image Data \n",
    "You are to perform preprocessing and exploratory analysis of a data set: exploring the statistical summaries of the features, visualizing the attributes, and addressing data quality. This report is worth 10% of the final grade. Please upload a report (one per team) with all code used, visualizations, and text in a rendered Jupyter notebook. Any visualizations that cannot be embedded in the notebook, please provide screenshots of the output.\n",
    "\n",
    "Dataset requirements: Choose a dataset that is comprised of image data. The data should be directories of images. That is, the dataset should not yet be pre-processed. The following are required for the dataset:\n",
    "\n",
    "The data includes at least 1000 images\n",
    "The size of the images should be larger than 20x20 pixels \n",
    "The dataset should have a well defined prediction task (i.e., a label for each image)\n",
    "The dataset cannot be MNIST or Fashion MNIST \n",
    "A note on grading: This lab is mostly about visualizing and understanding your dataset. The largest share of the points is from how you interpret the visuals that you make. Making the visuals is not enough to satisfy each of the rubrics belowâ€”you should appropriately explain what the implications of the visualizations are. In other words, expect about 20% of the available points for visuals that have no substantive discussion. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c26a290",
   "metadata": {},
   "source": [
    "Business Understanding (2 points total).  \n",
    "\n",
    "[2 points] Give an overview of the dataset. Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). What is the prediction task for your dataset and which third parties would be interested in the results? Why is this data important? Once you begin modeling, how well would your prediction algorithm need to perform to be considered useful to the identified third parties? Be specific and use your own words to describe the aspects of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef91d8",
   "metadata": {},
   "source": [
    "Data Preparation (1 points total)\n",
    "\n",
    "[.5 points] Read in your images as numpy arrays. Resize and recolor images as necessary. \n",
    "\n",
    "[.4 points] Linearize the images to create a table of 1-D image features (each row should be one image).   \n",
    "\n",
    "[.1 points] Visualize several images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abf27caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import necessary libraries\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.random_projection import johnson_lindenstrauss_min_dim\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import seaborn as sns\n",
    "\n",
    "# TODO: Load your images here\n",
    "# Define your data directory containing subfolders (class labels)\n",
    "data_dir = './your_dataset_path'\n",
    "\n",
    "# Initialize lists to store data and labels\n",
    "image_data = []\n",
    "labels = []\n",
    "\n",
    "# TODO: Implement your image loading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5012a",
   "metadata": {},
   "source": [
    "## 3. Data Reduction (6 points)\n",
    "\n",
    "### 3.1 Principal Component Analysis (0.5 points)\n",
    "Perform linear dimensionality reduction of the images using principal components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49652cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement PCA analysis\n",
    "# pca = PCA()\n",
    "# pca.fit(X)\n",
    "# Visualize explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84945b0f",
   "metadata": {},
   "source": [
    "### Analysis and Conclusion for PCA:\n",
    "[Insert your analysis of PCA results here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb760ef0",
   "metadata": {},
   "source": [
    "### 3.2 Randomized Principal Component Analysis (0.5 points)\n",
    "Perform linear dimensionality reduction of your image data using randomized principal components analysis. Visualize the explained variance of each component. Analyze how many dimensions are required to adequately represent your image data. Explain your analysis and conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b0870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement Randomized PCA analysis\n",
    "# from sklearn.decomposition import PCA\n",
    "# rpca = PCA(random_state=42)\n",
    "# rpca.fit(X)\n",
    "# Visualize explained variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676e5a9",
   "metadata": {},
   "source": [
    "### Analysis and Conclusion for Randomized PCA:\n",
    "[Insert your analysis of Randomized PCA results here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad810dd",
   "metadata": {},
   "source": [
    "### 3.3 Comparison of PCA vs Randomized PCA (2 points)\n",
    "Compare the representation using PCA and Randomized PCA. The method you choose to compare dimensionality methods should quantitatively explain which method is better at representing the images with fewer components. Do you prefer one method over another? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2235a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement comparison between PCA and Randomized PCA\n",
    "# Compare reconstruction error, explained variance, or other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9871bb77",
   "metadata": {},
   "source": [
    "### Comparison Analysis and Conclusion:\n",
    "[Insert your detailed comparison and preference here]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3d8ca",
   "metadata": {},
   "source": [
    "### 3.4 Feature Extraction Technique (1 point)\n",
    "Perform feature extraction upon the images using any feature extraction technique (e.g., gabor filters, ordered gradients, DAISY, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b0fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your chosen feature extraction technique\n",
    "# Options: Gabor filters, Ordered gradients, DAISY, SIFT, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2986ea",
   "metadata": {},
   "source": [
    "### 3.5 Feature Extraction Analysis (2 points)\n",
    "Does this feature extraction method show promise for your prediction task? Why? Use visualizations to analyze this question. For example:\n",
    "- Visualize the differences between statistics of extracted features in each target class\n",
    "- Use a heat map of the pairwise differences (ordered by class) among all extracted features\n",
    "- Build a nearest neighbor classifier to see actual classification performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c876bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Analyze the effectiveness of your feature extraction method\n",
    "# Create visualizations and metrics to evaluate performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c39308b",
   "metadata": {},
   "source": [
    "### Feature Extraction Analysis and Conclusion:\n",
    "[Insert your analysis of the feature extraction method and its promise for your prediction task]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1de09b",
   "metadata": {},
   "source": [
    "## 4. Exceptional Work (1 point)\n",
    "\n",
    "You have free reign to provide any additional analyses.\n",
    "\n",
    "### Optional: Advanced Feature Matching with DAISY\n",
    "*(Required for 7000 level students)*\n",
    "\n",
    "Perform feature extraction upon the images using DAISY. Rather than using matching on the images with the total DAISY vector, you will instead use key point matching. You will need to investigate appropriate methods for key point matching using DAISY. NOTE: this often requires some type of brute force matching per pair of images, which can be computationally expensive. Does it perform better than not using key point matching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db6f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement advanced analysis (optional/required based on course level)\n",
    "# This could include DAISY key point matching or other advanced techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cc60cc",
   "metadata": {},
   "source": [
    "### Exceptional Work Analysis:\n",
    "[Insert your additional analysis or findings here]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
